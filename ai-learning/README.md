# NOTES
## 01 base
This should be the simplest example to get started.  

The goal is to find out if it runs on very limited machines or if we are already over the limit of usability, because on following iterations we will push harder.
Based on a classic "sentiment" exercise, we add training data (very small) and see how the trained model perform in a word afterwards.

Results on Raspberry?:
TBD

## 02 labelling
Still on the sentiment exercise, this is already a full example from having a simple list of words to a rough estimation on any word.

The goal is to find out if I can create a model through my own manual training.  
Obviously there are two topics to improve in the next iteration:
- Add reinforcement at the predictor, which improves the training data "on the go"
- Even better, make that automatic, like in gaming (e.g.: "car hits wall is a failure", but for sentiments)

Results on Raspberry?:
TBD
